
# Intro to Data Science - Lab 11
##### Copyright 2022, Jeffrey Stanton and Jeffrey Saltz   Please do not post online.

## Week 11 - Text Mining

```{r}
# Enter your name here: Hongdi Li
```

### Please include nice comments. <br>
### Instructions: 
Run the necessary code on your own instance of R-Studio.

### Attribution statement: (choose only one and delete the rest)

```{r}
# 1. I did this lab assignment by myself, with help from the book and the professor.
```

**Text mining** plays an important role in many industries because of
the prevalence of text in the interactions between customers and company
representatives. Even when the customer interaction is by speech, rather than by
chat or email, speech to text algorithms have gotten so good that transcriptions of
these spoken word interactions are often available. <br><br>To an increasing extent, a data
scientist needs to be able to wield tools that turn a body of text into actionable
insights.<br><br>
In this exercise, we work with a small number of social media posts on the topic of
climate change. Make sure to install and library the **tidiverse**, **quanteda**, **quanteda.textplots**, and **quanteda.textstats** packages
before starting the exercise.

```{r}
library('tidyverse')
library('quanteda')
library('quanteda.textplots')
library('quanteda.textstats')
```

1. Read in the following data set with **read_csv()**:
https://intro-datascience.s3.us-east-2.amazonaws.com/ClimatePosts.csv <br>
The name of the file is ** ClimatePosts.csv **. Store the data in a data frame called **tweetDF**. Use **str(tweetDF)** to summarize the data. Add a comment describing
what you see. Make sure to explain what each of the three variables contains.

```{r}
tweetDF<-read.csv('https://intro-datascience.s3.us-east-2.amazonaws.com/ClimatePosts.csv')
str(tweetDF)
#There are only 3 variable which are ID, skeptic, and Tweet.
#ID and Tweet are char, Skeptic is number.
```

2. Use the **corpus** commands to turn the text variable into a quanteda corpus. You
can use the IDs as the document titles with the following command:<br><br>
`tweetCorpus <- corpus(tweetDF$Tweet, docnames=tweetDF$ID)`

```{r}
tweetCorpus <- corpus(tweetDF$Tweet, docnames=tweetDF$ID)
```

3. Next, convert the corpus into a **document-feature matrix (DFM)**. Before you do
that you can use ** tokens ** to remove punctuation and stop words. Use this code and comment each line:<br><br>


```
toks <- tokens(tweetCorpus, remove_punct=TRUE)
toks_nostop <- tokens_select(toks, pattern = stopwords("en"), selection = "remove")
```


Here s a command that will create the DFM:<br><br>
`tweetDFM <- dfm(toks_nostop, tolower = TRUE )`

```{r}
toks <- tokens(tweetCorpus, remove_punct=TRUE)
toks_nostop <- tokens_select(toks, pattern = stopwords("en"), selection = "remove")

tweetDFM <- dfm(toks_nostop, tolower = TRUE )
```

4. Type **tweetDFM** in the code cell to find out the basic characteristics of the DFM (the
number of terms, the number of documents, and the sparsity of the matrix).
Write a comment describing what you observe.

```{r}
tweetDFM
```

5. Create a **wordcloud** from the DFM using the following command. Write a
comment describing notable features of the wordcloud:<br><br>
`textplot_wordcloud(tweetDFM, min_count = 1)`

```{r}
textplot_wordcloud(tweetDFM, min_count = 1)
```

6. Using **textstat_frequency()** from the **quanteda.textstats** package, show the 10
most frequent words, and how many times each was used/mentioned.

```{r}
textstat_frequency(tweetDFM)
```

7. Next, we will read in **dictionaries** of positive and negative words to see what we
can match up to the text in our DFM. Here s a line of code for reading in the list of
positive words:<br><br>


```
URL <- "https://intro-datascience.s3.us-east-2.amazonaws.com/positivewords.txt"
posWords <- scan(URL, character(0), sep = "\n")
posWords <- posWords[-1:-34]
```

 <br><br>
Create a similar line of code to read in the negative words, with the following
URL:<br><br> https://intro-datascience.s3.us-east-2.amazonaws.com/negative-words.txt  <br><br>
There should be 2006 positive words and 4783 negative words.

```{r}

```

8. Explain what the following lines of code does and comment each line. Then add
similar code for the negative words.<br><br>


```
posDFM <- dfm_match(tweetDFM, posWords)
posFreq <- textstat_frequency(posDFM)
```


```{r}

```

9. Explore **posFreq** and **negFreq** using **str()** or **glimpse()**. Explain the fields in these data frames

```{r}

```

10. Output the 10 most frequently occurring positive and negative words
including how often each occurred.

```{r}

```

